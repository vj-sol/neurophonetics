<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="Vijay Solanki">

    <title>Neurophonetics</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/sky.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!--Add support for earlier versions of Internet Explorer -->
    <!--[if lt IE 9]>
<script src="lib/js/html5shiv.js"></script>
<![endif]-->

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <header style="position: absolute;top: 50px; left: 100px; z-index:500; background-color: rgba(0,0,0,0)"></header>
      <div class="slides">
        <section>
          <h2>Neurophonetics
          </h2>
          <h4>Vijay Solanki
          </h4>
          <div align='center'>
            <a href='mailto:v.solanki.1@research.gla.ac.uk'> <small>v.solanki.1@research.gla.c.uk</small></a>
            <br/>
          <small>University of Glasgow
          </small>
            <br/>
          <small>Thurs 9th March 2017
          </small>
          </div>
          <aside class = "notes">
            I am your notes!
          </aside>
        </section>

        <section>
          <section>
            <h2>What is Neurophonetics?</h2>
          </section>

          <section>
            <!--h3>What is Neurophonetics?</h3-->
            <blockquote align='left'>''Neurophonetics deals with neurogenic impairments of the motor act of speaking and of the perceptual processes of spoken language understanding, with the aim of unravelling the neural organization of speech motor control and speech perception.''
            </blockquote>
            <p align='right'>(Ziegler 2008: 491)</p>
          </section>

          <section>
            <!--h3>What is Neurophonetics?</h3-->
            <blockquote align='left'>''Neurophonetics aims at the elucidation of the brain mechanisms underlying speech communication in our species''
            </blockquote>
            <p align='right'>(Hertrich & Ackermann 2013)</p>
          </section>

          <section>
            <!--h3>What is Neurophonetics?</h3-->
            <blockquote align = 'left'>''To the extent that phonetics is a subdiscipline of linguistics, neurophonetics can be viewed as a subdiscipline of neurolinguistics''
            </blockquote>
            <p align='right'>(Ziegler 2008)</p>
          </section>
        </section>

        <section>
          <h3>Lecture Outline</h3>
          <ol>
            <li class='fragment' align='left'>Anatomy & Physiology of the Brain</li>
            <li class='fragment' align='left'>The WLG Model</li>
            <!--             <li class='fragment' align='left'>Measurement Tools</li> -->
            <li class='fragment' align='left'>Modern Advances</li>
            <ol>
              <li class='fragment' align='left' type = 'a'>Where?</li>
              <li class='fragment' align='left' type='a'>How?</li>
<!--               <li class='fragment' align='left' type='a'>The Integration Problem</li> -->
            </ol>
            <li class='fragment' align='left'>Conclusion</li>
          </ol>
          <aside class='notes'>
            <p>Learning Outcomes</p>
            <ul>
              <li>Acquire a basic understanding of the anatomy and Physiology of the human brain.</li>
              <li>Understand the beginnings of neurolinguistics (ie. the WLG model) and how the field has progressed.</li>
<!--               <li>Gain a rough understanding of modern neuroimaging techniques and their advantages/drawbacks.</li> -->
              <li>Develop a basic understanding of modern thinking behind neurolinguistics/phonetics</li>
              <li>Understand what some of the classic neurolinguistic imaging studies can tell us about language processing</li>
              <li>Develop knowledge of what additional anatomical structures in the brain contribute to language processing</li>
              <li>Gain a very basic insight into the direction that the field is heading</li>
            </ul>
            <p>By the end, it should be clear that the brain runs multiple functions simultaneously in order to interpret speech.</p>
          </aside>
        </section>

        <section>
          <h2>Warning slide</h2>
          <p>There will be some bloody(ish) images</p>
        </section>

        <section>

          <section>
            <h2>Anatomy and physiology of the brain</h2>
          </section>

          <section data-background='resources/ned2.gif' data-background-size=80%>
            <!--p>Test</p-->
            <!--             <img width=90% src='resources/ned2.gif' alt='Ned the Neuron'> -->
            <p>
              <br></br>
          <br></br>
        <br></br>
      <br></br>
    <br></br>
  <br></br>
<br></br>
</p>
<small style='color:white;background:#1B333F'>Illustration for Ned the Neuron, published by Kizoom in 2012.
</small>
<aside class='notes'>
  <p>This is generally a good way to think about the brain, although it does need a little refinement…
  </p>
</aside>
</section>

<section>
  <p align='left'>The brain is made of NEURONS and GLIAL CELLS (but glial cells are not discussed here)</p>
  <p align='left' class='fragment'>NEURONS are arranged into layers which allow for the efficient transfer of information, carried as electrical impulses</p>
  <p align='left' class='fragment'>NEURONAL LAYERS in different areas are arranged to maximise processing efficiency for the functions that they are required to perform and provide the basis for the larger structures of the brain</p>
  <aside class='notes'>
    <p>Essentially, you need to understand that the brain operates at many different levels in order to process incoming information and to integrate it with information already stored in memory.
    </p>
  </aside>
</section>

<section>
  <h2>Neurons</h2>
  <p align='left'>Neurons transmit information to other neurons or muscles (via the brain stem)
  </p>
  <p class='fragment' align='left'>FIRING: electrical ACTION POTENTIAL travels down AXON to SYNAPSE (junction)
  </p>
  <p class='fragment' align='left'>A NEUROTRANSMITTER is released which either EXCITES or INHIBITS the post-synaptic cell
  </p>
  <img src='./resources/giphy.gif' align='middle' class='fragment'>
</section>

<section>
  <p align='left'>MYELIN encases important connections, both to protect vital information transfer routes and to speed up transmission of the action potential
  </p>
  <img src='./resources/neurons.jpg' class='fragment' data-fragment-index='1' height='450px'>
  <img src='./resources/giphy-90.gif' class='fragment' data-fragment-index='2' height='450px'>
  <div class='fragment' data-fragment-index='1'>
  <small>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Web source 1.</small>
  </div>
  <aside class='notes'>
    <p>Arrows indicate the direction of conduction of action potentials in axons (red). </p>
    <p>(a) Multipolar interneurons. Each has profusely branched dendrites, which receive signals at synapses with several hundred other neurons, and a single long axon that branches laterally and at its terminus. </p>
    <p>(b) A motor neuron that innervates a muscle cell. Typically, motor neurons have a single long axon extending from the cell body to the effector cell. In mammalian motor neurons an insulating sheath of myelin usually covers all parts of the axon except at the nodes of Ranvier and the axon terminals. </p>
    <p>(c) A sensory neuron in which the axon branches just after it leaves the cell body. The peripheral branch carries the nerve impulse from the receptor cell to the cell body, which is located in the dorsal root ganglion near the spinal cord; the central branch carries the impulse from the cell body to the spinal cord or brain. Both branches are structurally and functionally axons, except at their terminal portions, even though the peripheral branch conducts impulses toward, rather than away from, the cell body.
    </p>
  </aside>
</section>

<section>
  <h3>
    Neuronal Layers
  </h3>
  <div style='float:right;'>
    <img class='fragment' data-fragment-index='1' src='./resources/neuro-layers.jpg'>
    <div class='fragment' data-fragment-index='1'>
    <small>Web source 2.</small>
    </div>
  </div>
  <p class='fragment' align='left'>
    Neurons are arranged into layers specific to the functions that they are required to perform
  </p>

  <p class = 'fragment' align='left'>
    Neurons that perform similar functions are LOCALISED to a particular region of the brain
  </p>
  <aside class='notes'>
    <p>All neurons are not created equal.</p>
    <p>
      The information that any given neuron or network of neurons is required to processes is specific to its location in the brain and is relative to those neurons that it is connected to.
    </p>
  </aside>
</section>

<section>
  <h2>Brain Structure</h2>
</section>

<section>
  <a href='http://www.g2conline.org/2022'>
    <h2>Genes to Cognition Online</h2>
  </a>
  <a href='http://www.g2conline.org/2022'>
    www.g2conline.org
  </a>
  <aside class='notes'>
    <p>Sections to take note of and explain include:
    <ul>
      <li>Each of the major lobes and what their functions seem to be</li>
      <ul>
        <li>Frontal = The frontal lobes are part of the cerebral cortex and are the largest of the brain's structures. They are the main site of so–called 'higher' cognitive functions. The frontal lobes contain a number of important substructures, including the prefrontal cortex, orbitofrontal cortex, motor and premotor cortices, and Broca's area. These substructures are involved in attention and thought, voluntary movement, decision–making, and language.</li>
        <li>Parietal = The parietal cortex plays an important role in integrating information from different senses to build a coherent picture of the world. It integrates information from the ventral visual pathways (which process what things are) and dorsal visual pathways (which process where things are). This allows us to coordinate our movements in response to the objects in our environment. It contains a number of distinct reference maps of the body, near space, and distant space, which are constantly updated as we move and interact with the world.       The parietal cortex processes attentional awareness of the environment, is involved in manipulating objects, and representing numbers.</li>
        <li>Temporal = The temporal lobes contain a large number of substructures, whose functions include perception, face recognition, object recognition, memory acquisition, understanding language, and emotional reactions. Damage to the temporal lobes can result in intriguing neurological deficits called agnosias, which refer to the inability to recognize specific categories (body parts, colors, faces, music, smells).</li>
        <li>Occipital = The occipital cortex is the primary visual area of the brain. It receives projections from the retina (via the thalamus) from where different groups of neurons separately encode different visual information such as color, orientation, and motion. Pathways from the occipital lobes reach the temporal and parietal lobes and are eventually processed consciously. Two important pathways of information originating in the occipital lobes are the dorsal and ventral streams. The dorsal stream projects to the parietal lobes and processes where objects are located. The ventral stream projects to structures in the temporal lobes and processes what objects are.</li>
      </ul>
      <li>Corpus Callosum</li>
      <li>Motor Cortex</li>
      <li>Somatosensory Cortex</li>
      <li>Primary Auditory Cortex</li>
      <li>Cerebellum</li>
      <li>Basal ganglia, thalamus, limbic system, hippocampus</li>
    </ul>
    </p>
  </aside>
</section>

<section>
  <h2>
    The Cerebrum
  </h2>
  <div align='left'>
    <p class='fragment'>
      Cerebrum = 2 hemispheres
    <p>
    <p class='fragment'>
      Each hemisphere is divided into 4 lobes:
    <ul>
      <li class='fragment'>
        Frontal
      </li>
      <li class='fragment'>
        Parietal
      </li>
      <li class='fragment'>
        Temporal
      </li>
      <li class='fragment'>
        Occipital
      </li>
    </ul>
    </p>
  </div>
<aside class='notes'>
</aside>
</section>

<section>
  <h2 valign='top'>
    The cerebral cortex
  </h2>
  <div align='left'>
    <p class='fragment'>Cerebral cortex = surface of cerebrum
    </p>
    <p class='fragment'>
      Cortex can be roughly divided into areas of functions
    <p class='fragment'>
      e.g. language, personality, vision, audition, motor and sensory functions
    </p>
  </div>
  <aside class='notes'>
  </aside>
</section>

<section data-background='resources/exposed-brain.jpeg' data-background-size=40%>
  <br></br>
<br></br>
<br></br>
<br></br>
<br></br>
<div align='middle'>
  <p>
    <br></br>
<br></br>
<small style='color:black;background-color:white; display: inline-block;'>
  Photograph by Robert Ludlow.
  Wellcome Trust Image Awards winner 2012.
</small>
</p>
</div>
<aside class='notes'>
  <p>This image is here to highlight the fact that when we talk about the “cortex”, we are only considering the outer layer of the brain and not the deep brain structures.</p>
  <p>Arteries (small red)
    Veins (big purple)
    “Grey matter” and “white matter”: but pink
    Intracranial recording for epilepsy. Surface of human brain in situ.
  </p>
  <p>
    Gyrus/Gyri = the outward folds of the cortex
    Sulcus/Sulci = the inward folds of the cortex
  </p>
</aside>
</section>

<section>
  <h3>
    Left & right hemispheres
  </h3>
  <div class='fragment' align='left'>
    Equal size/proportion, but different white/grey matter structures
  </div>
  <p class='fragment' align='left'>
    Different networks of connectivity
  </p>
  <div class='fragment' align='left'>
    Some functions are the same:
    <table>
      <td>
        MOVEMENT
        SENSATION
      </td>
      <td class='fragment'>
        Planning & execution cross sides
      </td>
    </table>
  </div>
  <div class='fragment' align='left'>
    However, some functions are different across the two hemispheres…
  </div>
  <aside class='notes'>
    So the left side of your brain controls the right side of your body, and the right side of your brain the left side
    Likewise information from your right eye goes to the left side of your brain, etc.
  </aside>
</section>

<!--       <section data-state='header 1'>
<style>.header header:after {content:'Left & right hemispheres';}
</style>
</section> -->

<section data-background='resources/left-right-brain.jpg'>
  <div>
    <h3>
      Left Brain – <span style='color:white'> Right Brain</span>
    </h3>
  </div>
  <div class='fragment'>
    <br></br>
  <h1  style='color:blue'>
    WRONG
  </h1>
  <p align='right'>
    <br></br>
<br></br>
<br></br>
<small style='color:white'>
  Nielsen, et al. (2013)
</small>
</p>
</div>
<aside class='notes'>
  You are not “Right-Brained” of “Left Brained” the hemispheres just have specific localised processing strengths.
  Both hemispheres are required to process information efficiently and effectively.
</aside>
</section>


<section>
  <h2>Hemispheric functions</h2>
  <p align='left'>
    Each hemisphere has specific processing strengths, eg:
  </p>
  <table>
    <tr>
      <th class='fragment' data-fragment-index='1'>Left Hemisphere</th>
      <th class='fragment' class='fragment' data-fragment-index='3'>Right Hemisphere</th>
    <tr>
      <td class='fragment' data-fragment-index='2'>
        Important for language processing, mathematical functioning

      </td>
      <td class='fragment' data-fragment-index='3'>
        Important for processing visual and spatial information
      </td>
    <tr>
      <td class='fragment' data-fragment-index='2'>
        (Hervé, et al. 2013, Jolles et al. 2015)
      </td>
      <td class='fragment' data-fragment-index='3'>(Hervé, et al. 2013)
      </td>
  </table>
  <aside class='notes'>
    Having said this, both hemispheres are required in order to correctly process speech.
  </aside>
</section>

<section>
  <h2>
    Within the cerebrum
  </h2>
  <div align='left'>
    <h4>
      Cortex (cerebrum surface):
    </h4>
    <ul class='fragment'>
      <li>Grey matter (nerve cell bodies)</li>
      <li>Some white matter</li>
    </ul>
    </p>
  </div>
<div align='left'>
  <h4 class='fragment'>
    Subcortical areas:
  </h4>
  <ul>
    <li class='fragment'>Grey matter</li>
    <li class='fragment'>White matter fibres (eg.):</li>
    <ul>
      <li class='fragment'>Corpus Callosum (connects right and left hemispheres)</li>
      <li class='fragment'>
        <div class='fragment highlight-red'>
          Arcuate Fasciculus
        </div>
        (connects motor and sensory cortices)
      </li>
    </ul>
  </ul>
</div>
<aside class='notes'>
  We will be coming back to discuss the function of the Arcuate Fasciculus in the next section
</aside>
</section>

</section>

</section>

<section>
  <section>
    <h2>
      The WLG Model
    </h2>
    <aside class='notes'>
    </aside>
  </section>

  <section data-background='resources/gage-skull.png' data-background-size=1oo%>
    <h2 style='color:black;background-color:white; display: inline-block;'>
      Phineas Gage
    </h2>
    <p style='color:black;background-color:white; display: inline-block;'>
      1823-1861, accident in 1848
    </p>
    <aside class='notes'>
    </aside>
  </section>

  <section>
    <h3 align='left'>Phineas Gage (1848)</h3>
    <table>
      <td>
        <img src='resources/gage-skull-dia.png' alt='Diagram of injury to Phineas Gage' style=height:500px>
      </td>
      <td>
        <img src='resources/gage-2012.png' alt='Diagram of injury to Phineas Gage' style=height:500px>
      </td>
    </table>
    <div align='right' style='font-size:80%'>Van Horn (2012)</div>
    <aside class='notes'>
      Gage was a railroad construction worker who suffered an unusual kind of traumatic brain injury which inflicted severe damage to parts of his frontal brain during a work accident.

      His case was so extraordinary that he is still studied.
    </aside>
  </section>

  <section>
    <h3 align='left'>Phineas Gage (1848)</h3>
    <h6 align='left'>Trauma to frontal lobe</h6>
    <div>
      <p class='fragment' style="font-size:80%;" align='left'>One of first cases to highlight role of frontal lobe in:</p>
      <ul>
        <li class='fragment' align='left' style="font-size:80%;">Personality</li>
        <li class='fragment' align='left' style="font-size:80%;">Emotional regulation</li>
        <li class='fragment' align='left' style="font-size:80%;">Decision making / Problem solving</li>
      </ul>
    </div>
    <p>
    <h6 class='fragment' align='left'>What does this suggest?</h6>
    <div>
      <ul>
        <li class='fragment' align='left' style="font-size:80%;">Specific brain functions are grouped in specialised regions</li>
        <li class='fragment' align='left' style="font-size:80%;">We say that brain function is LOCALISED</li>
      </ul>
    </div>
    </p>
  <aside class='notes'>
    <p>Gage reportedly had significant changes in personality and temperament, which provided some of the first evidence that specific parts of the brain, particularly the frontal lobes, might be involved in specific psychological processes dealing with emotion, personality and problem solving. </p>
    <p>Gage's case is cited as among the first evidence suggesting that damage to the frontal lobes could alter aspects of personality and affect socially appropriate interaction. Before this time the frontal lobes were largely thought to have little role in behaviour. </p>
    <p>This is essentially how we assessed the function of the various areas of the brain. We had to look for patients with “lesions” in the brain.</p>
    <p>These are known as “lesion studies”.</p>
  </aside>
</section>

<section align='left'>
  <h3>
    Brain Pathology and Language
  </h3>
  <p align='left'>Aphasia:</p>
  <div class='fragment' align='left'>
    <p>
      Loss or impairment of the ability to produce or comprehend language, due to brain damage
    </p>
  </div>
  <div class='fragment' align='left'>
    <p>Various types:</p>
    <ul>
      <li>Global</li>
      <li>Broca’s/motor</li>
      <li>Wernicke’s/jargon/anomic</li>
    </ul>
  </div>
  <aside class='notes'>
    Many types of APHASIA – here are some.
  </aside>
</section>

<section>
  <h2>Broca & Wernicke</h2>
  <table style='border:0px' width=100% height=100%>
    <tr class='fragment'>
      <td style='border:0px'>
        <img align='left' src='resources/Broca.jpg' alt='Paul Broca' style='height:250px;margin: 20px 20px'>
        <div>
          <p>
            Paul Broca (1824-1880)
          </p>
          <p style="font-size:70%;">
            Broca’s patient, ‘Tan’ – 1861:
          </p>
          <p style="font-size:70%;">Problem with production (only one syllable ‘tan’)</p>
          <p style="font-size:70%;">Large cyst in the left hemisphere (“mushy and deformed”)</p>
        </div>
      </td>
    </tr>
    <tr class='fragment'>
      <td>
        <img align='left' src='resources/Wernicke.jpg' alt='Karl Wernicke' style='height:250px;margin: 20px 20px'>
        <p>
          Karl Wernicke (1848-1905)
        </p>
        <p style="font-size:70%;">
          Wernicke’s patient – 1874:
        </p>
        <p style="font-size:70%;">Patient who could speak but couldn’t comprehend language</p>
        <p style="font-size:70%;">Lesion at the crossroads of 2 lobes of the brain</p>
      </td>
    </tr>
  </table>
  <aside class='notes'>
  </aside>
</section>

<section>
  <h2>Broca’s Area</h2>
  <div align='left'>
    <h3>Where?</h3>
    <p>Frontal lobe - Inferior frontal gyrus</p>
    <ul>
      <li>Pars opercularis</li>
      <li>Pars triangularis</li>
    </ul>
  </div>
  <div align='right'>
    <table style='border:0px'>
      <tr style='border:0px'>
        <td style='border:0px'>
          <img src='resources/Broca-large.jpg' alt='Brocas area, Anwander, et al. (2007)' style=width:300px align='right'>
        </td>
      </tr>
      <tr style='border:0px'>
        <td style='border:0px'>
          <p align='right'><small>Anwander, et al. (2007)</small></p>
        </td>
      </tr>
    </table>
  </div>
  <aside class='notes'>
  </aside>
</section>

<section>
  <h2>Broca’s Aphasia</h2>
  <div align='left' class='fragment'>
    <h3>Function</h3>
    <ul style='font-size:80%'>
      <li>Motor language area</li>
      <li>Expression</li>
    </ul>
  </div>
  <div align='left' class='fragment'>
    <h3>Aphasia</h3>
    <ul style='font-size:80%'>
      <li>Motor / non-fluent aphasia</li>
      <li>Good comprehension, no/impaired speech</li>
      <li>E.G. ‘boy go store’ vs ‘The boy has gone to the store’</li>
      <li>Slow, laboured, ungrammatical speech</li>
      <li>“yes…ah…Monday…ah…dad and…and…ah…hospital….and ah….Wednesday….Wednesday”</li>
    </ul>
  </div>
  <aside class='notes'>
    To understand the symptoms, recall that Broca's area controls expression, whereas Wernicke's area is responsible for comprehension.
  </aside>
</section>

<section>
  <iframe width='100%' height="600" src="https://www.youtube.com/embed/f2IiMEbMnPM" frameborder="0" allowfullscreen></iframe>
  <!--   http://youtu.be/f2IiMEbMnPM -->
  <aside class='notes'>
  </aside>
</section>

<section>
  <h2>Broca’s Area</h2>
  <div>
    <p align='left'>
      Photograph of the brain of Paul Broca’s patient called “Tan”
    </p>
    <table>
      <tr>
        <td>
          <img src='resources/tan-left.png' alt='Tan lesion, view from left hemisphere'>
        </td>
        <td>
          <img src='resources/tan-right.png' alt='Tan lesion, view from above'>
        </td>
      </tr>
    </table>
  </div>
  <aside class='notes'>
  </aside>
</section>

<section>
  <h2>Wernicke’s Area</h2>
  <div align='left'>
    <h3>Where?</h3>
    <p>Temporal/Parietal lobe</p>
    <ul>
      <li>Supramaringal gyrus</li>
      <li>Angular gyrus</li>
    </ul>
  </div>
  <div align='right'>
    <table style='border:0px'>
      <tr style='border:0px'>
        <td style='border:0px'>
          <img src='resources/Wernicke-large.jpg' alt='Wernicke area, Andoh, et al. (2008)' style=width:700px>
        </td>
      </tr>
      <tr style='border:0px'>
        <td style='border:0px'>
          <p align='right'><small>Andoh, et al. (2008)</small></p>
        </td>
      </tr>
    </table>
  </div>
  <aside class='notes'>
  </aside>
</section>

<section>
  <h2>Wernicke’s Aphasias</h2>
  <div align='left' class='fragment'>
    <h3>Function</h3>
    <ul style='font-size:80%'>
      <li>Sensory language area</li>
      <li>Comprehension</li>
    </ul>
  </div>
  <div align='left' class='fragment'>
    <h3>Aphasia</h3>
    <ul style='font-size:80%'>
      <li>Fluent / Receptive (cortical sensory) aphasia</li>
      <li>Defect in comprehension, good spontaneous speech</li>
      <li>Anomic aphasia - word finding difficulty</li>
      <ul>
        <li>Slow, laboured, ungrammatical speech</li>
        <li>Jargon aphasia - fluent, but unintelligible jargon</li>
      </ul>
    </ul>
  </div>
  <aside class='notes'>
  </aside>
</section>

<section>
  <iframe width="100%" height="600" src="https://www.youtube.com/embed/3oef68YabD0" frameborder="0" allowfullscreen></iframe>
  <aside class='notes'>
    <p>In WERNICKE’S aphasia - Patients can utter strings of speech which are grammatically ok but make NO SENSE.
      e.g word finding difficulties. E.g. table [chair]</p>
    <p>Wernicke’s area was generally thought to be the site for language comprehension but it also has a role in looking up word and funnelling them to other areas.</p>
  </aside>
</section>

<section>
  <h2>The WLG Model</h2>
  <div align='left' style='font-size:80%'>
    <img src='resources/Hagoort-2014-001.jpg' alt='Hagoort (2014), WLG model.' style='vertical-align:top; margin:0px 25px' width=500px height=450px align='right'/>
    <p>Broca’s and Wernicke’s areas are connected via the <span class='fragment highlight-red'>ARCUATE FASCICULUS</span></p>
    <p class='fragment'>This view was dominant for more than a century and still carries weight today</p>
    <p class='fragment'>It is known as the Wernicke-Lichtheim-Gerschwind Model (WLG model), named after those that helped to develop it</p>
    <div align='right'>
      <small>Hagoort (2014)</small>
    </div>
  </div>
  <aside class='notes'>
    <p>A link between the production and comprehension areas is necessary to produce a percept of language/speech, thus the WLG model was posited.</p>
    <p>Recall that the Arcuate Fasciculus is a bundle of WHITE MATTER which acts as an information transfer highway.</p>
  </aside>
</section>

<section>
  <h2>Summary</h2>
  <ul>
    <div class='fragment'>
      <li>Broca’s area</li>
      <ul>
        <li>Inferior frontal gyrus (frontal lobe)</li>
        <li>Good comprehension but impaired speech</li>
        <li>Seat of language production(?)</li>
      </ul>
    </div>
    <div class='fragment'>
      <li>Wernicke’s area</li>
      <ul>
        <li>Supramaringal/angular gyrus (temporal/parietal lobe)</li>
        <li>Good production but defect in comprehension</li>
        <li>Seat of language comprehension(?)</li>
      </ul>
    </div>
    <li class='fragment'>Both localised to left hemisphere</li>
    <li class='fragment'>They operate together as part of a larger network</li>
  </ul>
  <aside class='notes'>
    <p>This class of theories are known as the LOCALIST view</p>
    <p>They view functions in the brain as connected but fundamentally separate with only one function per area.</p>
  </aside>
</section>

</section>

<!-- <section>
<section><h2>Measurement Tools</h2></section>
<section>We’ve come a long way…

Traditional methods for interpreting brain function mainly involved LESION STUDIES
Not always possible to assess brain function IN-VIVO
Cannot be restricted to REGIONS OF INTEREST

Modern methods are somewhat more elegant…

Web Source [3]</section>
<section>Neuroimaging Techniques

Mehta & Parasuraman (2013)</section>
<section>Neuroimaging Techniques

Mehta & Parasuraman (2013)

Friederici

(2012 )

Tsiga, et al. (2014)

Kim, et al. (2014)</section>
<section>Diffusion Tensor Imaging / Tractography

Web Source [5]

Web Source [4]</section>
</section>
-->

<section>

  <section>
    <h2>Modern Advances</h2>
    <aside class='notes'>
    </aside>
  </section>

  <section>
    <h3>Where?</h3>
    <aside class='notes'>
      <p>The work presented here is predominently concerned with WHERE speech processing takes place.</p>
      <p>Although some work does detail the route that speech processing might take through the brain, localisation of function remains at the core.</p>
    </aside>
  </section>

  <section>
    <h3>Classic neuroimaging evidence about language processing</h3>
    <div align='left'>
      <img src='resources/scott-spect-2000.png'alt='Scott (2000), spectrogram.' style='vertical-align:top; margin:0px 25px' width=500px height=500px align='right'/>
      <a href='http://www.phon.ucl.ac.uk/home/brain/'><h4 style='color:blue'>
        Scott, et al (2000)
        </h4>
      </a>
      <div>
        <p class='fragment' data-fragment-index='5' style='font-size:50%'>Normal Speech (Sp)</p>
        <audio controls class='fragment' data-fragment-index='4'>
          <source src='resources/06_40.wav' type='audio/wav'>
        </audio>
        <p  class='fragment' data-fragment-index='5' style='font-size:50%'>Spectrally Rotated Speech (RSp)</p>
        <audio controls class='fragment' data-fragment-index='2'>
          <source src='resources/06_r40.wav' type='audio/wav'>
        </audio>
        <p class='fragment' data-fragment-index='5' style='font-size:50%'>Vocoded Speech (VCo)</p>
        <audio controls class='fragment' data-fragment-index='3'>
          <source src='resources/06_40n.wav' type='audio/wav'>
        </audio>
        <p  class='fragment' data-fragment-index='5' style='font-size:50%'>Rotated vocoded Speech (RVCo)</p>
        <audio controls class='fragment' data-fragment-index='1'>
          <source src='resources/06_r40n.wav' type='audio/wav'>
        </audio>
      </div>
    </div>
    <aside class='notes'>
      <p>Noise-vocoded speech is created by dividing the speech signal into logarithmically-spaced frequency bands.</p>
      <p>In each frequency band the amplitude envelope is extracted, and then used to modulate noise in the same frequency band.</p>
      <p>Finally each of the bands of noise are recombined to create the noise-vocoded sentence. Davis (2005)</p>
    </aside>
  </section>

  <section>
    <h3>Classic neuroimaging evidence about language processing</h3>
    <div align='left'>
      <img src='resources/scott-2000-small.png'alt='Scott (2000), spectrogram.' style='vertical-align:top; margin:0px 25px' width=500px height=500px align='right'/>
      <a href='http://www.phon.ucl.ac.uk/home/brain/'><h4 style='color:blue'>
        Scott, et al (2000)
        </h4> </a>
      <div style='font-size:80%'>
        <p><span style='color:red'>Red</span> = Responses to sounds with phonetic information</p>
        <p>ie. Sp, RSp & VCo</p>
        <p><span style='color:yellow'>Yellow</span> = Responses to sounds that are intelligible</p>
        <p>ie. Sp & VCo</p>
      </div>
      <aside class='notes'>
        <p>Used PET to obtain data.</p>
        <p>Demonstrates a different view to the WLG model as the temporal lobe is already separating input into un/intelligible categories even before reaching Wernicke’s area.</p>
        <p>This is a bit of an issue as comprehension was traditionally believed to occur in the supramaringal/angular gyrus.</p>
      </aside>
      </section>

    <section>
      <h3>Classic neuroimaging evidence about language processing</h3>
      <div align='left'>
        <image src='resources/davis-2003.jpg' alt='Findings of Davis and Johnsrude (2003)'style='float: right' width='60%' length='150%'/>
        <h4> Davis & Johnsrude (2003)</h4>
        <p style='font-size:80%'>
          English sentences, distorted in a variety of ways.
        </p>
        <p style='font-size:80%'>
          Looked for correlations between blood flow and intelligibility of speech sounds
        </p>
        <p style='font-size:60%' align='right'>
          Left: intelligible speech vs noise
        </p>
        <p style='font-size:60%' align='right'>
          Right: responses to different forms of distortion
        </p>
      </div>
      <aside class='notes'>
        <p>This is a good slide to introduce the notion of bottom-up and top-down processes.
          Remember: top-down modulation need not be language specific</p>
        <p>Davis and Johnsrude: more detailed study:
          Speech in noise, Segmented, Vocoded
          Left: These are the areas that light up when speech is intelligible as opposed to unintelligible
          Right: These are the areas that light up according to the form of the distortion (acoustics)</p>

        <p>What does this tell us?
          Higher order areas are recruited to improve the signal to noise ratio of the incoming speech signal if the signal is distorted. This is shown by the recruitment of more areas in the form independent condition. Those sounds that are clearly speech, do not require further processing, they can be dealt with in areas local to the primary auditory cortex.</p>

        <p>Additional information
          This study also demonstrated the inclusion of the left anterior hippocampus (involved in memory formation), suggests large, interconnected networks.
          However, this study also highlighted the dominant role of the left hemisphere in resolving perceptual ambiguity, finding only marginal activity in the right hemisphere.</p>
      </aside>
    </section>

    <section>
      <h3>Classic neuroimaging evidence about language processing</h3>
      <img src='resources/Hickock-2004.jpg' alt='Hickock (2004) diagram' style='vertical-align:top; margin:0px 25px' align='left' width=400px/>
      <p align='left'>Hickock & Poeppel (2004)</p>
      <div align='left' style='font-size:60%' class='fragment'>
        <p>Superior Temporal Gyrus</p>
        <ul>
          <li>Bilateral (both hemispheres)</li>
          <li>Acoustic-phonetic forms</li>
        </ul>
      </div>
      <div align='left' style='font-size:60%' class='fragment'>
        <p>Dorsal Stream (left only)</p>
        <ul>
          <li>Wernicke’s area</li>
          <li>Broca’s area</li>
          <li>Motor cortex</li>
          <li>Articulatory forms</li>
        </ul>
      </div>
      <div align='left' style='font-size:60%' class='fragment'>
        <p>Ventral Stream (left only)</p>
        <ul>
          <li>Posterior Inferior Temporal Lobe</li>
          <li>Sound-meaning interface</li>
        </ul>
      </div>
      <aside class='notes'>
        <p>“This model integrates language processing networks into the broader scheme of cortical functional anatomy. It provides a context to interpret the neural basis not only of “traditional” language functions (broadly defined), such as speech perception, auditory comprehension, and speech production, but also provides a natural account of verbal working memory.” (pp. 94)</p>
        <p>This view is often referred to as the 2-streams model, dorsal and ventral processing streams, which operate simultaneously</p>
      </aside>
    </section>

    <section>
      <h3>Lateralisation of language functions</h3>
      <table style='font-size:25px'>
        <tr>
          <th style='width:50%' align='center'>
            Left Hemisphere
          </th>
          <th style='width:50%' align='center'>
            Right Hemisphere
          </th>
        <tr>
          <td class='fragment'>
            <p>Traditionally thought to be dominant for language processing</p>
            <p>Preference for intelligible speech</p>
          </td>
          <td class='fragment'>
            <p>Damage may spare production and comprehension, but can lead to problems with: pragmatic ability, prosody, speaker characteristics (phonagnosia), recognition of music & environmental sounds</p>
          </td>
        </tr>
        <tr>
          <td class='fragment'>
            Possibly more sensitive to phonetic form with better time resolution (limited evidence)
          </td>
          <td class='fragment'>
            Possibly more sensitive to speaker characteristics with better frequency resolution (limited evidence)
          </td>
        </tr>
      </table>
      <br/>
      <small align='right'>Zatorre, et al. (2002); Scott, et al. (2009); Francis & Driscoll (2006); Friederici (2011)</small>
      <aside class='notes'>
        <p>
          Pinker (1994)
          “normal people recognise words more accurately when the words are flashed to the right side of the visual field than when flashed to the left”
          similar findings for ears
        </p>
      </aside>
    </section>

    <section>
      <h3>Lateralisation of language functions</h3>
      <img src='resources/valaki-2004.png' alt='Valaki (2004)' style='vertical-align:top; margin:0px 25px' align='right' width=500px/>
      <div align='left' style='font-size:80%'>
        <p>Spoken word recognition test, was used to establish cerebral dominance</p>
        <p>Lateralisation (%Ss):
        <ul style='width:35%'>
          <li>Spanish 100% left</li>
          <li>English 80% left</li>
          <li>Chinese 79% bilateral</li>
        </ul>
        </p>
      <p>(tone lang.)</p>
      </div>
    <br/>
    <p align='right'>
      Chinese English Spanish&nbsp;&nbsp;&nbsp;
    </p>
    <div  align='right'>
      <small>
        Valaki et al. (2004)
      </small>
    </div>
    <aside class='notes'>
      <p>large groups of native speakers
        of Mandarin Chinese/English/Spanish
        coronal MRI slices, data for 3 Ss, >200 ms post-stimulus onset</p>
    </aside>
  </section>

  <section>
    <h3>Language Processing Beyond the Cortex</h3>
    <table style='font-size:50%'>
      <tr>
        <th align='center' style='width:305px;font-size:130%;border:0px' class='fragment' data-fragment-index='1'>
          Cerebellum
        </th>
        <th align='center' style='width:385px;font-size:130%;border:0px' class='fragment' data-fragment-index='5'>
          Basal Ganglia
        </th>
        <th align='center' style='width:365px;font-size:130%;border:0px' class='fragment' data-fragment-index='9'>
          Thalamus
        </th>
        <th align='center' style='width:280px;font-size:130%;border:0px' class='fragment' data-fragment-index='12'>
          Hippocampus
        </th>
      </tr>
      <tr>
        <td class='fragment' data-fragment-index='1' style='border:0px'>
          <img src='resources/Cerebellum.png'/>
        </td>
        <td class='fragment' data-fragment-index='5' style='border:0px'>
          <img src='resources/Basal-Ganglia.png'/>
        </td>
        <td class='fragment' data-fragment-index='9' style='border:0px'>
          <img src='resources/Thalamus.png'/>
        </td>
        <td class='fragment' data-fragment-index='12' style='border:0px'>
          <img src='resources/Hippocampus.png'/>
        </td>
      </tr>
      <tr>
        <td class='fragment' data-fragment-index='2' style='border:0px'>Co-ordinates muscle groups to produce smooth speech & swallowing.</td>
        <td class='fragment' data-fragment-index='6' style='border:0px'>Controls muscles of face, larynx, tongue and pharynx</td>
        <td class='fragment' data-fragment-index='10' style='border:0px'>Inner chamber determines which sensory information to forward to cortex</td>
        <td class='fragment' data-fragment-index='13' style='border:0px'>Long-term memory, language comprehension, word-generation</td>
      </tr>
      <tr>
        <td class='fragment' data-fragment-index='3' style='border:0px'>Helps integrate sensory perception and motor output.
        <td class='fragment' data-fragment-index='7' style='border:0px'>Damage can lead to lack of coordination and facial expression (e.g. Parkinson’s)</td>
        <td class='fragment' data-fragment-index='11' style='border:0px'>Damage can lead to deficits in memory, attention, reduced spontaneous speech</td>
        <td class='fragment' data-fragment-index='14' style='border:0px'>Damage (severe in Alzheimer's) can lead to word-finding difficulties</td>
      </tr>
      <tr>
        <td class='fragment' data-fragment-index='4' style='border:0px'>Damage can lead to slurring of speech</td>
        <td class='fragment' data-fragment-index='8' style='border:0px'>Also disruption to rhythm and temporal processing</td>
      </tr>
    </table>
    <!--
Parkinson’s speech sample

courtesy of Dr Anja Lowit (Strathclyde) -->
    <aside class='notes'>
    </aside>

  </section>

  <section>
    <h3>Neural correlates of phonetic skill</h3>
    <h4 align='left'>Born with an ear for dialects?</h4>
    <ul style='font-size:80%'>
      <li class='fragment'>In naïve (English) listeners, an individual’s brain structure in left auditory cortex, parietal cortex, and left inferior frontal cortex partly predicts their ability to discriminate a difficult contrast (Hindi dental vs. retroflex) <p>(Golestani et al., 2002, 2007)</p></li>
      <li class='fragment'>In phoneticians, years of transcription experience correlate with size of left pars opercularis <p>(Golestani et al., 2011)</p></li>
      <li class='fragment'>Phoneticians are also more likely to have multiple or split left transverse gyri in auditory cortex (thought to develop in utero)</li>
    </ul>
    <aside class='notes'>
      <p>Re final point: authors say “this gross morphological difference may have existed before the onset of phonetic training, and … its presence confers an advantage of sufficient magnitude to affect career choices”</p>
    </aside>
  </section>

  <section>
    <h3>How?</h3>
    <!--     <ul>
<li>Behavioural data
(whole brain)</li>
<li>Localised neuro-functional data
(brain areas)</li>
<li>Localised anatomical data
(brain areas)</li>
<li>Connectivity data
(neuronal networks)
?</li> -->
    </ul>
  <aside class='notes'>
    <p>The work presented here concerns HOW speech is processed by the brain.</p>
    <p>The main focus is on the way in which the underling archetecture of the brain aids in speech processing</p>
  </aside>
</section>

<section>
  <h3>Phineas Gage - Modern Insights</h3>
  <img src='resources/gage-2012.png' alt='Diagram of injury to Phineas Gage' style='vertical-align:top; margin:0px 25px' align='center' width=400px>
  <br/>
  <small>Van Horn, et al. (2012)</small>
  <aside class='notes'>
    <p>By assessing the famous case of Phineas Gage Van Horn et al (2012) with Diffusion Weighted Imaging (DWI) and Magnetic Resonance Imaging (MRI) they were able to determine that only 4% of Mr. Gage’s grey matter was destroyed in comparison to  11% of his white matter.</p>
    <p>They conclude that although frontal lobe damage most certainly contributed to the functional deficits and personality changes that Mr. Gage suffered after his accident, the degree of white matter which was removed would have severely impacted on the manner in which his brain processed information.</p>
    <p>The role of white matter is just as important in understanding the mechanics of the human brain as the role of grey matter.</p>
  </aside>
</section>

<section>
  <a href='http://onpub.cbs.mpg.de/' data-preview-link>
    Friederici (2011) – Web Link, Firefox & Chrome Only
  </a>

  <aside class='notes'>
    <p>This link demonstrates the white matter connections which are linked to linguistic functioning in the brain. They are fro more extensive than suggested by the WLG model and are somewhat more in keeping with the 2-streams model, with a dorsal and ventral processing route.</p>
  </aside>
</section>

<section>
  <h3>Neuronal Oscillations</h3>
  <table>
    <tr>
      <td>
        <img src='resources/eeg-readings.jpg' alt='Neuron action potential gif' align='left' width=90%/>
      </td>
      <td style='width:20%;vertical-align:middle' align='left'>
        <img src='resources/giphy-90.gif' alt='Neuron action potential gif' align='center' height='800px'/>
      </td>
    </tr>
  </table>
  <div align='right'>
    <small align='right'>Kim, et al. (2014)</small>
  </div>
  <!--     <div align='right'>
<small align='right'>Kim, et al. (2014)</small>
</div> -->
</section>

<section>
  <h3>Neuronal Coherence</h3>
  <div>
  <video controls width='85%'>
    <source src='resources/Neurophonetics.mp4' type=video/mp4>
  </video>
  <div align='left'>
    <small>Adapted from Fries (2005)</small>
    <br/>
    <small>Also see: Bastos, et al. (2015); Brunet, et al. (2015)</small>
  </div>
  </div>
  <aside class='notes'>
    <p>Animations on this slide demonstrate how oscillatory behaviour can be modelled in terms of individual communicating neurons. It also demonstrates how information can be separated into redundant and useful. This could potentially help to explain exactly how the brain determines which information can be directly interpreted in the primary auditory cortex and close areas from information which requires further processing in higher areas.</p>
  </aside>
</section>

<section>
  <h3>Neuronal Oscillations</h3>
  <img src='resources/giraud-poeppel-2012-1.png'/>
  <div align='right'>
    <small>Giraud & Poeppel (2012)</small>
  </div>
  <aside class='notes'>
    <p>Giraud & Poeppel (2012)</p>
    <p>In this article, we have articulated a set of hypotheses to investigate the relation between the perception of connected speech and neurobiological mechanisms. We developed a model at anatomic (Figs. 3 and 6), physiological (Figs. 1, 2 and 4) and computational (Fig. 5) levels. At the center of the research program lies the assumption that cortical oscillations provide ways to temporally organize the incoming speech signal. The main emerging principles are that two prerequisites for constructing intelligible representations of the speech stream are phase-locking between stimulus and cortex in (at least) two discrete time domains and the hierarchical coupling of related cortical oscillations during speech processing.</p>
    <p>Critique - Oblesser, et al. (2012)</p>
    <p>In sum, we argue that an overly enthusiastic focus on speech envelope and concomitantly a too narrow focus on theta oscillations, 	or the readiness to force all slower neural oscillations into a theta 	straightjacket, might not get us closer to the neural mechanics of 	speech comprehension. Without visionary, synergistic perspectives like the one offered by Giraud and Poeppel (2012) we will not 	make it there either. </p>
    <p>Gross et al. (2013)</p>
    <p>In summary, we report a nested hierarchy of auditory oscillations at multiple frequencies that match the frequency of
      relevant linguistic components in continuous speech. These oscillations entrain to speech with differential hemispheric
      preference for high (left) and low (right) frequencies. Our results indicate that temporal edges in speech increase first the coupling between auditory oscillations across frequency bands and, second, their coupling to the speech envelope.
      We can only speculate about the nature of the observed phase/amplitude alignments. Most likely the alignments are caused by a combination of modulatory and evoked effects [55,56] where stimulus-driven activity is top-down modulated via ongoing oscillatory activity [30,61]. In this framework oscillatory activity is a mechanism for attentional selection and flexible gating of information from primary sensory areas.
      Finally, going beyond speech perception, the entrainment of hierarchically organized oscillations between speaker and
      listener may well have a more general role in interpersonal communication [62,63].</p>
  </aside>
</section>

<section>
  <h3>Neuronal Oscillations</h3>
  <img src='resources/giraud-poeppel-2012-2.png'/>
  <div align='right'>
    <small>Giraud & Poeppel (2012)</small>
  </div>
  <aside class='notes'>
    <p>Giraud & Poeppel (2012)</p>
    <p>In this article, we have articulated a set of hypotheses to investigate the relation between the perception of connected speech and neurobiological mechanisms. We developed a model at anatomic (Figs. 3 and 6), physiological (Figs. 1, 2 and 4) and computational (Fig. 5) levels. At the center of the research program lies the assumption that cortical oscillations provide ways to temporally organize the incoming speech signal. The main emerging principles are that two prerequisites for constructing intelligible representations of the speech stream are phase-locking between stimulus and cortex in (at least) two discrete time domains and the hierarchical coupling of related cortical oscillations during speech processing.</p>
    <p>Critique - Oblesser, et al. (2012)</p>
    <p>In sum, we argue that an overly enthusiastic focus on speech envelope and concomitantly a too narrow focus on theta oscillations, 	or the readiness to force all slower neural oscillations into a theta 	straightjacket, might not get us closer to the neural mechanics of 	speech comprehension. Without visionary, synergistic perspectives like the one offered by Giraud and Poeppel (2012) we will not 	make it there either. </p>
    <p>Gross et al. (2013)</p>
    <p>In summary, we report a nested hierarchy of auditory oscillations at multiple frequencies that match the frequency of
      relevant linguistic components in continuous speech. These oscillations entrain to speech with differential hemispheric
      preference for high (left) and low (right) frequencies. Our results indicate that temporal edges in speech increase first the coupling between auditory oscillations across frequency bands and, second, their coupling to the speech envelope.
      We can only speculate about the nature of the observed phase/amplitude alignments. Most likely the alignments are caused by a combination of modulatory and evoked effects [55,56] where stimulus-driven activity is top-down modulated via ongoing oscillatory activity [30,61]. In this framework oscillatory activity is a mechanism for attentional selection and flexible gating of information from primary sensory areas.
      Finally, going beyond speech perception, the entrainment of hierarchically organized oscillations between speaker and
      listener may well have a more general role in interpersonal communication [62,63].</p>
  </aside>
</section>

<section>
  <h3>Neuronal Oscillations</h3>
  <div align='center'>
  <div style='width:60%'>
  <img src='resources/giraud-poeppel-2012-3.png' align='center'/>
  </div>
  </div>

  <div align='right'>
    <small>Giraud & Poeppel (2012)</small>
  </div>
  <aside class='notes'>
    <p>Giraud & Poeppel (2012)</p>
    <p>In this article, we have articulated a set of hypotheses to investigate the relation between the perception of connected speech and neurobiological mechanisms. We developed a model at anatomic (Figs. 3 and 6), physiological (Figs. 1, 2 and 4) and computational (Fig. 5) levels. At the center of the research program lies the assumption that cortical oscillations provide ways to temporally organize the incoming speech signal. The main emerging principles are that two prerequisites for constructing intelligible representations of the speech stream are phase-locking between stimulus and cortex in (at least) two discrete time domains and the hierarchical coupling of related cortical oscillations during speech processing.</p>
    <p>Critique - Oblesser, et al. (2012)</p>
    <p>In sum, we argue that an overly enthusiastic focus on speech envelope and concomitantly a too narrow focus on theta oscillations, 	or the readiness to force all slower neural oscillations into a theta 	straightjacket, might not get us closer to the neural mechanics of 	speech comprehension. Without visionary, synergistic perspectives like the one offered by Giraud and Poeppel (2012) we will not 	make it there either. </p>
    <p>Gross et al. (2013)</p>
    <p>In summary, we report a nested hierarchy of auditory oscillations at multiple frequencies that match the frequency of
      relevant linguistic components in continuous speech. These oscillations entrain to speech with differential hemispheric
      preference for high (left) and low (right) frequencies. Our results indicate that temporal edges in speech increase first the coupling between auditory oscillations across frequency bands and, second, their coupling to the speech envelope.
      We can only speculate about the nature of the observed phase/amplitude alignments. Most likely the alignments are caused by a combination of modulatory and evoked effects [55,56] where stimulus-driven activity is top-down modulated via ongoing oscillatory activity [30,61]. In this framework oscillatory activity is a mechanism for attentional selection and flexible gating of information from primary sensory areas.
      Finally, going beyond speech perception, the entrainment of hierarchically organized oscillations between speaker and
      listener may well have a more general role in interpersonal communication [62,63].</p>
  </aside>
</section>

</section>

<section>
  <section><h2>Conclusion?</h2></section>
  <section>
    <p>“it takes the whole brain and, by extension, the whole person to participate in producing and perceiving a voice”</p>
    <p align='right'><small>Sidtis & Kreiman (2011)</small></p>
    <aside class='notes'>
    </aside>
  </section>

</section>

<section align='left'>
  <section>
    <h2 align='middle'>References</h2>
  </section>
  <section>
    <small align='left'>Andoh, J., Artiges, E., Pallier, C., Riviиre, D., Mangin, J.-F., Paillиre-Martinot, M.-L. & Martinot, J.-L. (2008). Priming frequencies of transcranial magnetic stimulation over Wernicke's area modulate word detection.. Cerebral cortex (New York, N.Y. : 1991) 18 (1), 210--6.
    </small>
    <br></br>
  <small align='left'>Anwander, A., Tittgemeyer, M., von Cramon, D. Y., Friederici, A. D. & Knцsche, T. R. (2007). Connectivity-Based Parcellation of Broca's Area.. Cerebral cortex (New York, N.Y. : 1991) 17 (4), 816--25.
  </small>
  <br></br>
<small align='left'>Bastos, A. M., Vezoli, J. & Fries, P. (2015). Communication through coherence with inter-areal delays. Current Opinion in Neurobiology 31, 173--180.
</small>
<br></br>
<small align='left'>Brunet, N., Vinck, M., Bosman, C. A., Singer, W. & Fries, P. (2014). Gamma or no gamma, that is the question. Trends in Cognitive Sciences 18 (10), 507--509.
</small>
</section>
<section>
  <small align='left'>Davis, M. H. & Johnsrude, I. S. (2003). Hierarchical Processing in Spoken Language Comprehension. J. Neurosci. 23 (8), 3423--3431.
  </small>
  <br></br>
<small align='left'>Feng, S., Legault, J., Yang, L., Zhu, J., Shao, K. & Yang, Y. (2015). Differences in grammatical processing strategies for active and passive sentences: An fMRI study. Journal of Neurolinguistics 33 (0), 104--117.
</small>
<br></br>
<small align='left'>Francis, A. L. & Driscoll, C. (2006). Training to use voice onset time as a cue to talker identification induces a left-ear/right-hemisphere processing advantage.. Brain and language 98 (3), 310--8.
</small>
<br></br>
<small align='left'>Friederici, A. D. (2011). The brain basis of language processing: from structure to function.. Physiological reviews 91 (4), 1357--92.
</small>
</section>
<section>
  <small align='left'>Friederici, A. D. (2012). The cortical language circuit: from auditory perception to sentence comprehension. Trends in Cognitive Sciences 16 (5), 262--268.
  </small>
  <br></br>
<small align='left'>Fries, P., et al. (2005). A mechanism for cognitive dynamics: neuronal communication through neuronal coherence. Trends in cognitive sciences 9 (10), 474--480.
</small>
<br></br>
<small align='left'>Ghitza, O., Giraud, A.-L. & Poeppel, D. (2012). Neuronal oscillations and speech perception: critical-band temporal envelopes are the essence.. Frontiers in human neuroscience 6 (340), 340.
</small>
<br></br>
<small align='left'>Giraud, A.-L. & Poeppel, D. (2012). Cortical oscillations and speech processing: emerging computational principles and operations.. Nature neuroscience 15 (4), 511--7.
</small>
</section>
<section>
  <small align='left'>Golestani, N., Molko, N., Dehaene, S., LeBihan, D. & Pallier, C. (2007). Brain structure predicts the learning of foreign speech sounds.. Cerebral cortex (New York, N.Y. : 1991) 17 (3), 575--82.
  </small>
  <br></br>
<small align='left'>Golestani, N., Paus, T. & Zatorre, R. J. (2002). Anatomical Correlates of Learning Novel Speech Sounds. Neuron 35 (5), 997--1010.
</small>
<br></br>
<small align='left'>Golestani, N., Price, C. J. & Scott, S. K. (2011). Born with an ear for dialects? Structural plasticity in the expert phonetician brain.. The Journal of neuroscience : the official journal of the Society for Neuroscience 31 (11), 4213--20.
</small>
<br></br>
<small align='left'>Gross, J., Hoogenboom, N., Thut, G., Schyns, Philippe Phillippe, Panzeri, S., Belin, P., Garrod, S. & Stefano, P. (2013). Speech rhythms and multiplexed oscillatory sensory coding in the human brain.. PLoS biology 11 (12), e1001752.
</small>
</section>
<section>

  <small align='left'>Hagoort, P. (2014). Nodes and networks in the neural architecture for language: Broca's region and beyond.. Current opinion in neurobiology 28C, 136--141.
  </small>
  <br></br>
<small align='left'>Hertrich, I. & Ackermann, H. (2013). Neurophonetics. Wiley Interdisciplinary Reviews: Cognitive Science 4 (2), 191--200.
</small>
<br></br>
<small align='left'>Hervé, P.-Y., Zago, L., Petit, L., Mazoyer, B. & Tzourio-Mazoyer, N. (2013). Revisiting human hemispheric specialization with neuroimaging.. Trends in cognitive sciences 17 (2), 69--80.
</small>
<br></br>
<small align='left'>Hickok, G. & Poeppel, D. (2004). Dorsal and ventral streams: a framework for understanding aspects of the functional anatomy of language.. Cognition 92 (1-2), 67--99.
</small>
<br></br>
</section>
<section>

  <small align='left'>Jolles, D., Wassermann, D., Chokhani, R., Richardson, J., Tenison, C., Bammer, R., Fuchs, L., Supekar, K. & Menon, V. (2015). Plasticity of left perisylvian white-matter tracts is associated with individual differences in math learning. Brain Structure and Function, 1--15.
  </small>
  <br></br>
<small align='left'>Kim, J., Lee, S.-K. & Lee, B. (2014). EEG classification in a single-trial basis for vowel speech perception using multivariate empirical mode decomposition. Journal of Neural Engineering 11 (3), 36010--36021.
</small>
<br></br>
<small align='left'>Mehta, R. K. & Parasuraman, R. (2013). Neuroergonomics: A Review of Applications to Physical and Cognitive Work. Frontiers in Human Neuroscience 7 (889).
</small>
<br></br>
<small align='left'>Nielsen, J. A., Zielinski, B. A., Ferguson, M. A., Lainhart, J. E. & Anderson, J. S. (2013). An evaluation of the left-brain vs. right-brain hypothesis with resting state functional connectivity magnetic resonance imaging.. PloS one 8 (8), e71275.
</small>
</section>
<section>

  <small align='left'>Obleser, J., Herrmann, B. & Henry, M. J. (2012). Neural oscillations in speech: don't be enslaved by the envelope. Frontiers in Human Neuroscience 6.
  </small>
  <br></br>
<small align='left'>Scott, S. K. (2000). Identification of a pathway for intelligible speech in the left temporal lobe. Brain 123 (12), 2400--2406.
</small>
<br></br>
<small align='left'>Scott, S. K., McGettigan, C. & Eisner, F. (2009). A little more conversation, a little less action–candidate roles for the motor cortex in speech perception.. Nature reviews. Neuroscience 10 (4), 295--302.
</small>
<br></br>
<small align='left'>Sidtis, D. & Kreiman, J. (2012). In the beginning was the familiar voice: personally familiar voices in the evolutionary and contemporary biology of communication. Integrative psychological & behavioral science 46 (2), 146--59.
</small>
</section>
<section>
  <small align='left'>Tsigka, S., Papadelis, C., Braun, C. & Miceli, G. (2014). Distinguishable neural correlates of verbs and nouns: A MEG study on homonyms. Neuropsychologia 54 (0), 87--97.
  </small>
  <br></br>
<small align='left'>Valaki, C. E., Maestu, F., Simos, P. G., Zhang, W., Fernandez, A., Amo, C. M., Ortiz, T. M. & Papanicolaou, A. C. (2004). Cortical organization for receptive language functions in Chinese, English, and Spanish: a cross-linguistic MEG study. Neuropsychologia 42 (7), 967--79.
</small>
<br></br>
<small align='left'>Van Horn, J. D., Irimia, A., Torgerson, C. M., Chambers, M. C., Kikinis, R. & Toga, A. W. (2012). Mapping Connectivity Damage in the Case of Phineas Gage. PLoS ONE 7 (5), e37454.
</small>
<br></br>
<small align='left'>Zatorre, R. J., Belin, P. & Penhune, V. B. (2002). Structure and function of auditory cortex: music and speech. Trends in cognitive sciences 6 (1), 37--46.
</small>
</section>
<section>
  <small align='left'>Ziegler, W. (2009). Neurophonetics. In The Handbook of Clinical Linguistics (pp. 491--505). Blackwell Publishing Ltd. (ISBN: 9781444301007.)
  </small>
</section>
</section>
<section>
  <section>
    <h2>Web Sources</h2>
  </section>
  <section>
    <ol>
      <li><a align='left' href='http://www.rijnlandmodel.nl/achtergrond/psychologie/neurologie_neuronen_algemeen.htm'>rijnlandmodel.nl
        </a></li>
      <br></br>
    <li><a align='left' href='http://thebrain.mcgill.ca/flash/d/d_02/d_02_cl/d_02_cl_vis/d_02_cl_vis.html'>thebrain.mcgill.ca
      </a></li>
<!--     <br></br>
  <li><a align='left' href='http://neuropathology-web.org/chapter2/chapter2bCerebralinfarcts.html'>neuropathology-web.org
    </a></li>
  <br></br>
<li><a align='left' href='http://www.kgu.de/bic/common.html'>kgu.de
  </a></li>
<br></br> -->
<!-- <li><a align='left' href='http://cfmm.robarts.ca/tools/3t-mri/'>cfmm.robarts.ca
  </a></li> -->
</ol>
</section>
</section>
</div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
  // More info https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
    height:800,
    width:960,
    margin: 0.1,
    minScale: 0.2,
    maxScale:1.5,
    // Display controls in the bottom right corner
    controls: true,

    // Display a presentation progress bar
    progress: true,

    // Display the page number of the current slide
    slideNumber: false,

    // Push each slide change to the browser history
    history: true,

    // Enable keyboard shortcuts for navigation
    keyboard: true,

    // Enable the slide overview mode
    overview: true,

    // Vertical centering of slides
    center: true,

    // Enables touch navigation on devices with touch input
    touch: true,

    // Loop the presentation
    loop: false,

    // Change the presentation direction to be RTL
    rtl: false,

    // Randomizes the order of slides each time the presentation loads
    shuffle: false,

    // Turns fragments on and off globally
    fragments: true,

    // Flags if the presentation is running in an embedded mode,
    // i.e. contained within a limited portion of the screen
    embedded: false,

    // Flags if we should show a help overlay when the questionmark
    // key is pressed
    help: true,

    // Flags if speaker notes should be visible to all viewers
    showNotes: false,

    // Number of milliseconds between automatically proceeding to the
    // next slide, disabled when set to 0, this value can be overwritten
    // by using a data-autoslide attribute on your slides
    autoSlide: 0,

    // Stop auto-sliding after user input
    autoSlideStoppable: true,

    // Use this method for navigation when auto-sliding
    autoSlideMethod: Reveal.navigateNext,

    // Enable slide navigation via mouse wheel
    mouseWheel: false,

    // Hides the address bar on mobile devices
    hideAddressBar: true,

    // Opens links in an iframe preview overlay
    previewLinks: false,

    // Transition style
    transition: 'slide', // none/fade/slide/convex/concave/zoom

    // Transition speed
    transitionSpeed: 'default', // default/fast/slow

    // Transition style for full page slide backgrounds
    backgroundTransition: 'concave', // none/fade/slide/convex/concave/zoom

    // Number of slides away from the current that are visible
    viewDistance: 3,

    // Parallax background image
    parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

    // Parallax background size
    parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

    // Number of pixels to move the parallax background per slide
    // - Calculated automatically unless specified
    // - Set to 0 to disable movement along an axis
    parallaxBackgroundHorizontal: null,
    parallaxBackgroundVertical: null,

    // More info https://github.com/hakimel/reveal.js#dependencies
    dependencies: [
      { src: 'lib/js/classList.js', condition: function ()
       { return !document.body.classList;}},
      { src: 'plugin/markdown/marked.js' },
      { src: 'plugin/markdown/markdown.js' },
      { src: 'plugin/notes/notes.js', async: true },
      { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () { return !!document.body.classList; } },
      { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
    ]
  });
  Reveal.configure({ pdfMaxPagesPerSlide: 1 });
</script>
</body>
</html>
